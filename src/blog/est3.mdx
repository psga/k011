---
title: Regression and Prediction
date: "2021-11-02"
description: "REGRESSION"
---
## Simple linear Regression
Simple Linear Regression Simple linear regression provides a model of the relationship between the magnitude of one variable and that of a second for example, as X increases, Y also increases. Or as X increases, Y decreases.1 Correlation is another way to measure how two variables are related see. Stimates how much Y will change when X changes by a certain amount. With the correlation coefficient, the variables X and Y are interchangeable, With regression, we are trying to predict the Y variable from X using a linear relationship

$$Y_{i}=b_{0}+b_{1}X_{i}+e_{i}$$

$$\hat{Y}_{i}=\hat{b}_{0}+\hat{b}_{1}X_{i}$$

- __Response__ The variable we are trying to predict.
 _Synonyms dependent variable, Y variable, target, outcome_

- __Independent variable__ The variable used to predict the response.
_Synonyms X variable, feature, attribute, predictor_

- __Record__ The vector of predictor and outcome values for a specific individual or case.
_Synonyms row, case, instance, example_

- __Intercept__ The intercept of the regression line—that is, the predicted value when X = 0. 
_Synonyms b0, β0_

- __Regression coefficient__ The slope of the regression line. 
_Synonyms slope, b1, β1, parameter estimates, weights_

- __Fitted values__ The estimates Yi obtained from the regression line. 
_Synonym predicted values_

- __Residuals__ The difference between the observed values and the fitted values.
_Synonym errors_

- __Least squares__ The method of fitting a regression by minimizing the sum of squared residuals.
_Synonym Ordinary least squares, OLS_

## Multiple Linear Regression
All of the other concepts in simple linear regression, such as fitting by least squares and the definition of fittied values and residuals,extend to the multiple linear regression setting.

$$Y=b_{0}+b_{1}X_{1}+b_{2}X_{2}+b_{3}X_{3}+...+b_{p}X_{p}+e_{i}$$

- __Root mean squared error__ The square root of the average squared error of the regression. _RMSE_
- __Residual standard error__ The same as the root mean squared error, but adjusted for degrees of freedom. _RSE_
- __R-squared__ The proportion of variance explained by the model, from 0 to 1 _coefficient of determination_
- __t-statistic__ The coefficient for a predictor,divided by the standard error of the coefficient,giving a metric to compare the importance of variables in the model. See "t-Tests"
- __Weighted regression__ Regression with the records having different weights
scikit-learn's LinearRegression can be used for multiple linear regression as well:
``` cpp
predictors=['SqFtTotLiving','SqFtLot','Bathrooms','Bedrooms','BldgGrade']
outcome = 'AdjSalePrice'
house_lm = LinearRegression()
house_lm.fit(house[predictors],house[outcome])
``` 
```cpp
house_lm
Call:
lm(formula = AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms +Bedrooms + BldgGrade, data = house, na.action = na.omit)
Coefficients:
(Intercept)      SqFtTotLiving        SqFtLot              Bathrooms
-5.219e+05       2.288e+02            -6.047e-02           -1.944e+04      
Bedrooms      BldgGrade
-4.777e+04      1.061e+05
```

$$
R M S E=\sqrt{\frac{\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}{n}}
$$

$$
R S E=\sqrt{\frac{\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}{(n-p-1)}}
$$

