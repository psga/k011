{"componentChunkName":"component---src-components-blogpost-blogpost-jsx","path":"/blog/alg3/","result":{"data":{"site":{"siteMetadata":{"title":"K011"}},"mdx":{"id":"0f0086ad-9798-5e2f-885f-c57d4ee8f8ed","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Algorithms Search\",\n  \"date\": \"2021-07-26\",\n  \"description\": \"BFS & DFS\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", null, \"Linear Search\"), mdx(\"p\", null, \"linear search or sequence search is a method of finding a target value within the list.\\nIt consist of going through and examing each of the elements of the array until we find the element(s) we are looking for, or until we have looked at all the elements of the array.\"), mdx(\"p\", null, \"This is the slowest search method, but if our information is completely disordered, it is the only one that can help us find the data we are looking for.\"), mdx(\"center\", null, mdx(\"img\", {\n    className: \"w-60-l \",\n    src: \"https://imgur.com/9UaTiEP.gif\"\n  })), mdx(\"h2\", null, \"Binary Search\"), mdx(\"p\", null, \"Binary search works on ordered arrays. It consists of eliminating half of the elements of the array on which the search is performed after each comparison, it starts comparing the elements in te middle of the array with the searched value. If the searched value is equal to the middle element, its position in the array is returned. if the searched value is less or greater than the middle element, the search will cotinue in the first or second half, respectively, leaving the other half out of consideration; and if they are equal, the searched value has been found and the position is returned\\nwould function as a binary tree\"), mdx(\"center\", null, mdx(\"img\", {\n    className: \"w-60-l \",\n    src: \"https://imgur.com/yWJHmFH.gif\"\n  })), mdx(\"h1\", null, \"Graph / Tree  traversal\"), mdx(\"p\", null, \"In an unordered tree or in a network how can we search for items?. For this there are 2 algorithms:\"), mdx(\"center\", null, mdx(\"img\", {\n    className: \"w-60-l \",\n    src: \"https://imgur.com/XGy4i4e.gif\"\n  })), mdx(\"h2\", null, \"Breadth First Search\"), mdx(\"p\", null, \"Is another technique for traversing a graph. BFS visits the sibling vertices before visiting the child vertices, and a queue is used in the search process. this algorithm is ofted used to find the shortest path from one vertex to another.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"class Graph:\\n    def __init__(self):\\n        self.graph = defaultdict(list)\\n    def addEdge(self,u,v):\\n        self.graph[u].append(v)\\n \\n    def BFS(self, s):\\n \\n        visited = [False] * (max(self.graph) + 1)\\n        queue = []\\n \\n        queue.append(s)\\n        visited[s] = True\\n        \\n        while queue:\\n            s = queue.pop(0)\\n            print (s, end = \\\" \\\")\\n            for i in self.graph[s]:\\n                if visited[i] == False:\\n                    queue.append(i)\\n                    visited[i] = True\\n\")), mdx(\"h4\", null, \"PROS AND CONS\"), mdx(\"p\", null, \"This algorithm is used when the location of the node is believed to be at a high level, it is  located above.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Pros\"), \": Shortest Path, Closer Nodes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Cons\"), \": More memory\")), mdx(\"h2\", null, \"Depth First Search\"), mdx(\"p\", null, \"this algorithm visits the child vertices before visiting the sibling vertices.\\nThe algorithm begins with a chosen \\\"root\\\" vertex; it then iteratively transitions from the current vertex to an adjacent, unvisited vertex, until it can no longer find an unexplored vertex to transition to from this current location\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"class Graph:\\n    def __init__(self):\\n        self.graph = defaultdict(list)\\n  \\n    def addEdge(self, u, v):\\n        self.graph[u].append(v)\\n  \\n    # A recursive function used by DFS\\n    def DFSUtil(self, v, visited):\\n        visited.add(v)\\n        print(v, end=' ')\\n        for neighbour in self.graph[v]:\\n            if neighbour not in visited:\\n                self.DFSUtil(neighbour, visited)\\n  \\n    def DFS(self, v):\\n        visited = set()\\n        self.DFSUtil(v, visited)\\n\")), mdx(\"h4\", null, \"PROS AND CONS\"), mdx(\"p\", null, \"This algorithm is used when the location of the node is believed to be at a low level, it is  located above.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Pros\"), \": Less Memory, Does path Exist?\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Cons\"), \": Can get slow\")), mdx(\"h1\", null, \"Shortest path\"), mdx(\"h2\", null, \"Dijkstra\"), mdx(\"p\", null, \"The most efficient way to find the minimum distance between two vertices of a graph with non-negative weights is using dijkstra's algorithm. The main idea of the algorithm is very simple: we will build a graph f, initially consisting only of the origin node. At each step we will look at all the nodes that we can reach directly from F, i.e. those that share an edge with a node of F, and we will ad the node whose distance to the origin is minimum , We will stop the algorithm when a vertex to be included to F is the destination node.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def dijsktra(graph, initial, end):\\n    # shortest paths is a dict of nodes\\n    # whose value is a tuple of (previous node, weight)\\n    shortest_paths = {initial: (None, 0)}\\n    current_node = initial\\n    visited = set()\\n    \\n    while current_node != end:\\n        visited.add(current_node)\\n        destinations = graph.edges[current_node]\\n        weight_to_current_node = shortest_paths[current_node][1]\\n\\n        for next_node in destinations:\\n            weight = graph.weights[(current_node, next_node)] + weight_to_current_node\\n            if next_node not in shortest_paths:\\n                shortest_paths[next_node] = (current_node, weight)\\n            else:\\n                current_shortest_weight = shortest_paths[next_node][1]\\n                if current_shortest_weight > weight:\\n                    shortest_paths[next_node] = (current_node, weight)\\n        \\n        next_destinations = {node: shortest_paths[node] for node in shortest_paths if node not in visited}\\n        if not next_destinations:\\n            return \\\"Route Not Possible\\\"\\n        # next node is the destination with the lowest weight\\n        current_node = min(next_destinations, key=lambda k: next_destinations[k][1])\\n    \\n    # Work back through destinations in shortest path\\n    path = []\\n    while current_node is not None:\\n        path.append(current_node)\\n        next_node = shortest_paths[current_node][0]\\n        current_node = next_node\\n    # Reverse path\\n    path = path[::-1]\\n    return path\\n\")), mdx(\"h2\", null, \"Bellman\"), mdx(\"p\", null, \"this algorithm is used like a alternative to Dijikstra algorthm, is very useful if the graph has negative weights\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"\\nclass Graph:\\n \\n    def __init__(self, vertices):\\n        self.V = vertices # No. of vertices\\n        self.graph = []\\n \\n    # function to add an edge to graph\\n    def addEdge(self, u, v, w):\\n        self.graph.append([u, v, w])\\n         \\n    # utility function used to print the solution\\n    def printArr(self, dist):\\n        print(\\\"Vertex Distance from Source\\\")\\n        for i in range(self.V):\\n            print(\\\"{0}\\\\t\\\\t{1}\\\".format(i, dist[i]))\\n     \\n    # The main function that finds shortest distances from src to\\n    # all other vertices using Bellman-Ford algorithm. The function\\n    # also detects negative weight cycle\\n    def BellmanFord(self, src):\\n \\n        # Step 1: Initialize distances from src to all other vertices\\n        # as INFINITE\\n        dist = [float(\\\"Inf\\\")] * self.V\\n        dist[src] = 0\\n \\n \\n        # Step 2: Relax all edges |V| - 1 times. A simple shortest\\n        # path from src to any other vertex can have at-most |V| - 1\\n        # edges\\n        for _ in range(self.V - 1):\\n            # Update dist value and parent index of the adjacent vertices of\\n            # the picked vertex. Consider only those vertices which are still in\\n            # queue\\n            for u, v, w in self.graph:\\n                if dist[u] != float(\\\"Inf\\\") and dist[u] + w < dist[v]:\\n                        dist[v] = dist[u] + w\\n \\n        # Step 3: check for negative-weight cycles. The above step\\n        # guarantees shortest distances if graph doesn't contain\\n        # negative weight cycle. If we get a shorter path, then there\\n        # is a cycle.\\n \\n        for u, v, w in self.graph:\\n                if dist[u] != float(\\\"Inf\\\") and dist[u] + w < dist[v]:\\n                        print(\\\"Graph contains negative weight cycle\\\")\\n                        return\\n                         \\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Algorithms Search","date":"2021-07-26","description":"BFS & DFS"}},"allMdx":{"edges":[{"node":{"frontmatter":{"title":"Recursion","date":"2021-08-26","description":"Algorithm recursion"},"fields":{"slug":"/blog/alg1/"}}},{"node":{"frontmatter":{"title":"Sorting algorithms","date":"2021-08-26","description":"Bubble sort .o0"},"fields":{"slug":"/blog/alg2/"}}},{"node":{"frontmatter":{"title":"RSA","date":"2021-08-14","description":"Modular arithmetic, cryptography"},"fields":{"slug":"/blog/RSA/"}}},{"node":{"frontmatter":{"title":"what happens when we access a webpage","date":"2021-07-26","description":"ka"},"fields":{"slug":"/blog/backend_1/"}}},{"node":{"frontmatter":{"title":"Array Data Structures","date":"2021-07-26","description":"Arrays Data Structures"},"fields":{"slug":"/blog/dt1/"}}}]}},"pageContext":{"slug":"/blog/alg3/","id":"0f0086ad-9798-5e2f-885f-c57d4ee8f8ed"}},"staticQueryHashes":["63159454"]}