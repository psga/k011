{"componentChunkName":"component---src-components-blogpost-blogpost-jsx","path":"/blog/BigO/","result":{"data":{"site":{"siteMetadata":{"title":"K011"}},"mdx":{"id":"d09914da-581d-5c8f-aaf8-aeb07cd4b8da","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Big O\",\n  \"date\": \"2021-07-16\",\n  \"description\": \"Simetry and Asymetry cryptoghy. Tokens \"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Big O\"), mdx(\"p\", null, \"First we must know what it is to have a good code.\"), mdx(\"h2\", null, \"Good Code\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A good code is when it is readable\"), \": that is, it is clear and clean and can be easily understood by reading it. When it is not necessary a lot of comments explaining what each thing does.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"A good code is when it is scalable\"), \":and this is where the term Big O notation comes in.\"), mdx(\"p\", null, \"Most problems do not have only one solution. They have several, an infinity of them.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"How do we know which code to use?\")), mdx(\"h2\", null, \"General idea\"), mdx(\"p\", null, \"The general idea is that we compare how fast the execution time of the algorithms grows with respect to the size of its input or the memory it uses. This is what Big O notation is all about. It is written with O and its scalability. For example, if we type an algorithm like this\"), mdx(\"h4\", null, \"O(1)\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def ole(n):\\n    print(\\\"OLEE\\\")\\n\")), mdx(\"p\", null, \"As we can see this function does not depend on the size of the input, its execution time is constant. So it is O(1)\"), mdx(\"p\", null, \"or we can also see this other example\"), mdx(\"h4\", null, \"O(n)\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def elemnts(list):\\n    for i in list:\\n        print(i)    \\n\")), mdx(\"p\", null, \"As we see this function depends on the size of the input, when the list has a size of 2 the condition will be repeated 2 times, when the list has a size of 3 the condition will be repeated 3 times, so it is said to be linear or O(n).\"), mdx(\"p\", null, \"This is the most common big O, y como pueden pensar existen muchos mas aqui una grafica \"), mdx(\"center\", null, mdx(\"img\", {\n    src: \"https://i.imgur.com/CNTKnZ3.png\"\n  })), mdx(\"h2\", null, \"Calculate\"), mdx(\"p\", null, \"The way to find the Big O notation of an algorithm is not difficult, it is just to calculate the bit O notation of each, so to speak, \\\"line\\\". A example:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def nitemsandsearchhola(list):\\n    nelements=0\\n    for element in list:\\n        nelements+=1\\n        if \\\"hola\\\"==element:\\n            print(\\\"Hola!\\\")\\n    print(\\\"there are {} items in the list\\\".format(nelements))       \\n\")), mdx(\"p\", null, \"calculating the big O notation of an algorithm is easy, but it can be interpreted in many ways. Most people calculate this by looking at for example \\\"Each line\\\" and calculating its big O notation independently and adding it up, the strange thing is that for some people some lines are not worth it, for example let's look at this example\"), mdx(\"p\", null, \"Some people may calculate this example like this:\"), mdx(\"img\", {\n    src: \"https://i.imgur.com/4lyB0rQ.png\"\n  }), mdx(\"p\", null, \"and others may see it like this:\"), mdx(\"img\", {\n    src: \"https://i.imgur.com/R06Pr6W.png\"\n  }), mdx(\"p\", null, \"because they think that the other lines are not worth enough (they do not scale).\"), mdx(\"h4\", null, \"Worst case\"), mdx(\"p\", null, \"That big-O refers to the worst case of an algorithm, i.e., think of a search algorithm that goes through a list to find a number or a word that we want (i.e., when the word enters it prints that it found it). We know that this is not the best solution (that goes through the whole list), because it can be in the first element of the list, the algorithm will find it and will continue with the cycle going through the whole algorithm. One way to organize this is to break the loop when it finds it.\\nOne code is more efficient than another, but they have the same BIg-o notation (O(n)) since Big-O notation refers to the worst case.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"in the best algorithm the cycle can be done 1 time as well as the number of items.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"in the worst case algorithm the cycle will always repeat the condition the number of times\")), mdx(\"p\", null, \"Let's look at the best algorithm\\nWe know it is O(n) since O(n) refers to the worst case. But what about the worst case?\\nFor this there is Big-Omega the algorithm will have \\u03A9(1) since it can be in the first element and will be independent of the number in the list. \"), mdx(\"h4\", null, \"Simplify\"), mdx(\"p\", null, \"To make the calculation of O(n) more general, i.e. to avoid the example of the function nitemsandsearchhola (O(4n+2) and O(n)), the constants are eliminated.\\nthe O(4n+2) in \\\"4n+2\\\" is eliminated the 2 and the 4 Thus it would be O(n)\\nOr if we get an O(n/8+20000) eliminating the constants we would have O(n).\\nOr an O(790000) would be O(1)\"), mdx(\"h3\", null, \"more than one entry\"), mdx(\"p\", null, \"Suppose I have this function:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def lists(a,b):\\n    for i in a:\\n        print(i)\\n    for i in b:\\n        print(i)\\n\")), mdx(\"p\", null, \"when calculating we would be left with O(2n) and simplifying O(n). If it would be right?\\nthe answer is that not if we see the 2 cycles go through a different list so a correct answer to this would be O(a+b)\"), mdx(\"h4\", null, \"Removing the non-dominant\"), mdx(\"p\", null, \"Suppose we have O(2n+n^2+5) Simplifying, i.e. removing the constants we would have O(2n+n^2) A question we can ask ourselves is if we can simplify more, the answer to this question is yes, removing those that are not dominant (the dominant being the heaviest), for example in O(2n+n^2) we can remove 2n since n^2 is heavier with this we would be left with O(n^2).\"), mdx(\"h3\", null, \"O(n^2)\"), mdx(\"p\", null, \"which algorithms are those that are O(n^2). these are the algorithms that have 2 nested cycles. Why?\\nlet's see an example \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def li(a):\\n    for i in a:\\n        for z in a:\\n            print(i,\\\"_\\\",z)\\n\")), mdx(\"p\", null, \"As we can see there are 2 nested cycles. the print will be repeated n times and each of those times will be repeated n times.\"), mdx(\"center\", null, \"(it1+it2+it3+it4+...+itn)+(it1+it2+it3+it4+...+itn)+(it1+it2+it3+it4+...+itn)..\", mdx(\"p\", null, \"n+n+n+n+n+....\"), mdx(\"p\", null, \"n*n\"), mdx(\"p\", null, \"n^2\")), \"what would happen with independent variables? Suppose that in the example of the function lists(a,b) were nested cycles, what is inside the cycle would be repeated a times and that would be repeated b times or the other way around. So it would remain O(a*b)\", mdx(\"h3\", null, \"O(n!)\"), mdx(\"p\", null, \"in the previous graph showed that the worst O was the n^2, i.e. the O with the fastest scalability.\\nBut there is one that is worse which is the O(n!) \\\"Oh no\\\" is the one that has one cycle for each item. an example to see this is the recursive algorithm:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def fun(n):\\n    for s in range(n):\\n        fun(n-1)\\n\")), mdx(\"h4\", null, \"Big O\"), mdx(\"p\", null, \"We can classify the algorithmic complexity of some algorithms as follows\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O(1)\"), \" \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Constant\"), \" This is when there are no loops, i.e. the code runs only once.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O(log N)\"), \" \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Logarithmic\"), \" usually searching algorithms have log n if they are sorted (an example of this is binary search).\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O(n)\"), \" \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Linear\"), \" for loops, It is when there are cycles that run n elements.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O(n log(n))\"), \" \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Log Liniear\"), \"- usually sorting operations .\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O(n^2)\"), \" \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Quadratic\"), \"- every element in a collection needs to be compared to ever other element. \"))), mdx(\"h2\", null, \"A Code Scalable\"), mdx(\"p\", null, \"We said that having a good code is when it is scalable but in addition to speed, there is also memory, the best is to keep very little memory usage and a lot of speed, but there are times when you have to have priorities, that is, when you need more speed you make a sacrifice of memory, and there are other times when you need to use less memory so you make a sacrifice in lowering the speed.\"), mdx(\"h3\", null, \"Space complexity\"), mdx(\"p\", null, \"Previously the memory was very limited, but now it is not like that. Computers now have a lot of memory so it made programmers relax about this problem.\\nThere are some algorithms that require a lot of memory and it is necessary to optimize it.\"), mdx(\"h4\", null, \"What causes space complexity?\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Variables\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data Structures\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Function Call\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Allocation\\nin space, 2 things must be taken into account\\nthe heap and the stack\")), mdx(\"h4\", null, \"Heap and stack\"), mdx(\"p\", null, \"in space complexity 2 things must be taken into account\\nthe heap and the stack\"), mdx(\"h3\", null, \"Speed Complexity\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Big O","date":"2021-07-16","description":"Simetry and Asymetry cryptoghy. Tokens "}},"allMdx":{"edges":[{"node":{"frontmatter":{"title":"Recursion","date":"2021-08-26","description":"Algorithm recursion"},"fields":{"slug":"/blog/alg1/"}}},{"node":{"frontmatter":{"title":"RSA","date":"2021-08-14","description":"Modular arithmetic, cryptography"},"fields":{"slug":"/blog/RSA/"}}},{"node":{"frontmatter":{"title":"what happens when we access a webpage","date":"2021-07-26","description":"ka"},"fields":{"slug":"/blog/backend_1/"}}},{"node":{"frontmatter":{"title":"Array Data Structures","date":"2021-07-26","description":"Arrays Data Structures"},"fields":{"slug":"/blog/dt1/"}}},{"node":{"frontmatter":{"title":"Hash tables Data Structures","date":"2021-07-26","description":"Hash tables Data Structures"},"fields":{"slug":"/blog/dt2/"}}}]}},"pageContext":{"slug":"/blog/BigO/","id":"d09914da-581d-5c8f-aaf8-aeb07cd4b8da"}},"staticQueryHashes":["63159454"]}